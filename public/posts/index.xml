<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Random thoughts</title>
    <link>https://arielassaf.com/posts/</link>
    <description>Recent content in Posts on Random thoughts</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://arielassaf.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rate of Progress Part 1: The Value of Intelligence</title>
      <link>https://arielassaf.com/posts/rate-of-progress-1/</link>
      <pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://arielassaf.com/posts/rate-of-progress-1/</guid>
      <description>&lt;p&gt;Everyone and their toaster is predicting that AI will change everything. Whole industries vaporized. All jobs obsolete—next week, apparently. You, jobless and serene, writing haikus in a meadow while a bot files your taxes, wins a Pulitzer, and gets optioned for a Netflix series.&lt;/p&gt;
&lt;p&gt;The only question: &lt;strong&gt;what calendar are these predictors using?&lt;/strong&gt;&lt;br&gt;
Where does the exuberance come from?&lt;/p&gt;
&lt;h2 id=&#34;it-starts-with-our-overvaluation-of-intelligence&#34;&gt;It starts with our overvaluation of intelligence&lt;/h2&gt;
&lt;p&gt;Intelligence, as it turns out, might be one of the most &lt;strong&gt;overrated traits of all time&lt;/strong&gt;.&lt;br&gt;
It doesn&amp;rsquo;t make people happier. Or kinder. Or better at relationships.&lt;/p&gt;</description>
    </item>
    <item>
      <title>It&#39;s an Alien Intelligence: Stop Comparing It to a Child</title>
      <link>https://arielassaf.com/posts/alien_intelligence/</link>
      <pubDate>Sat, 15 Mar 2025 12:00:00 +0000</pubDate>
      <guid>https://arielassaf.com/posts/alien_intelligence/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re obsessed with measuring AI against human children—as if that&amp;rsquo;s some gold standard for intelligence. It&amp;rsquo;s like judging a spaceship by how well it floats. Completely absurd.&lt;/p&gt;
&lt;p&gt;LLMs aren&amp;rsquo;t children. They&amp;rsquo;re not growing up, going to school, or worrying about acne. They aren&amp;rsquo;t mini-humans waiting to mature. They&amp;rsquo;re something altogether stranger, an &lt;strong&gt;alien intelligence&lt;/strong&gt;, shaped by &lt;strong&gt;statistical patterns&lt;/strong&gt; instead of evolution, neurons, playground drama, and awkward teenage sex.&lt;/p&gt;
&lt;p&gt;Sure, when we try to humanize them, LLMs come across as &lt;strong&gt;idiot savants&lt;/strong&gt;— regurgitating detailed trivia one second and stumbling over basic logic the next. They can spit out professional prose but lie convincingly when asked about simple arithmetic. But measuring them this way is fundamentally misguided. It’s like mocking a &lt;strong&gt;dolphin for its inability to ride a bicycle&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Move 37: How Far Will We Trust AI?</title>
      <link>https://arielassaf.com/posts/move_37_how_far_will_we_trust_ai/</link>
      <pubDate>Thu, 06 Mar 2025 12:00:00 +0000</pubDate>
      <guid>https://arielassaf.com/posts/move_37_how_far_will_we_trust_ai/</guid>
      <description>&lt;p&gt;Here is another attempt to think about AI more than a few weeks into the future.&lt;/p&gt;
&lt;p&gt;I started thinking about this after reading The MANIAC by Benjamín Labatut. In case you’re unfamiliar, John von Neumann was the man behind an astonishingly long list of contributions to humanity, including game theory and the modern computer. If I had met him and we disagreed, I would assume that he knew more, considered more, and analyzed it better than I did—that I was only seeing part of the picture.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
