<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Random thoughts</title>
    <link>https://arielassaf.com/posts/</link>
    <description>Recent content in Posts on Random thoughts</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Mar 2025 12:00:00 +0000</lastBuildDate>
    <atom:link href="https://arielassaf.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>It&#39;s an Alien Intelligence: Stop Comparing It to a Child</title>
      <link>https://arielassaf.com/posts/alien_intelligence/</link>
      <pubDate>Sat, 15 Mar 2025 12:00:00 +0000</pubDate>
      <guid>https://arielassaf.com/posts/alien_intelligence/</guid>
      <description>&lt;p&gt;We&amp;rsquo;re obsessed with measuring AI against human children—as if that&amp;rsquo;s some gold standard for intelligence. It&amp;rsquo;s like judging a spaceship by how well it floats. Completely absurd.&lt;/p&gt;
&lt;p&gt;LLMs aren&amp;rsquo;t children. They&amp;rsquo;re not growing up, going to school, or worrying about acne. They aren&amp;rsquo;t mini-humans waiting to mature. They&amp;rsquo;re something altogether stranger, an &lt;strong&gt;alien intelligence&lt;/strong&gt;, shaped by &lt;strong&gt;statistical patterns&lt;/strong&gt; instead of evolution, neurons, playground drama, and awkward teenage sex.&lt;/p&gt;
&lt;p&gt;Sure, when we try to humanize them, LLMs come across as &lt;strong&gt;idiot savants&lt;/strong&gt;— regurgitating detailed trivia one second and stumbling over basic logic the next. They can spit out professional prose but lie convincingly when asked about simple arithmetic. But measuring them this way is fundamentally misguided. It’s like mocking a &lt;strong&gt;dolphin for its inability to ride a bicycle&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Move 37: How Far Will We Trust AI?</title>
      <link>https://arielassaf.com/posts/move_37_how_far_will_we_trust_ai/</link>
      <pubDate>Thu, 06 Mar 2025 12:00:00 +0000</pubDate>
      <guid>https://arielassaf.com/posts/move_37_how_far_will_we_trust_ai/</guid>
      <description>&lt;p&gt;Here is another attempt to think about AI more than a few weeks into the future.&lt;/p&gt;
&lt;p&gt;I started thinking about this after reading The MANIAC by Benjamín Labatut. In case you’re unfamiliar, John von Neumann was the man behind an astonishingly long list of contributions to humanity, including game theory and the modern computer. If I had met him and we disagreed, I would assume that he knew more, considered more, and analyzed it better than I did—that I was only seeing part of the picture.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
